[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CASA0023 Learning Diary",
    "section": "",
    "text": "Introduction\nWelcome to my learning diary"
  },
  {
    "objectID": "week1.html#summary",
    "href": "week1.html#summary",
    "title": "1  Week 1: Getting started with remote sensing",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 The concept of remote sensing\nRemote sensing is the process of gathering data about a phenomenon or object without actually coming into touch with it. The phrase is used particularly in reference to learning more about Earth and other planets. It refers to the detection and classification of Earthly objects using satellite or aircraft-based sensor technologies. Based on transmitted signals, it encompasses the atmosphere, the surface, and the oceans (e.g. electromagnetic radiation).\nIt can be divided into “active” and “passive” remote sensing.\nActive: where a signal is emitted to the object by a satellite or aircraft and its reflection is detected by the sensor\nPassive: when the reflection of sunlight is detected by the sensor\n\n\n\nSchematic of active and passive remote sensing\n\n\n\n\n1.1.2 Open source raster data\nThere are many open source raster data from aerial photography and satellites, in our course, we use Sentinel data and Landsat data:\n\nSentinel: Data is provided by the Copernicus Space Component Data Access (CSCDA), operated by the European Space Agency (ESA).\nLink: https://scihub.copernicus.eu/dhus/#/home\nLandsat: Data is provided by the U.S. Geological Survey (USGS).\nLink: https://earthexplorer.usgs.gov/\n\n\n\n1.1.3 Piece of work\nI learned how to access remote sensing data using two open source databases, Landsat and Copernicus Open Access Hub, their existence make it easy for me to access remote sensing data from anywhere in the world.\nSecondly, I learned how to use QGIS, SNAP and some packages in R for simple raster processing calculations and also learned a lot about the terminology, remote sensing and statistics and also having some questions."
  },
  {
    "objectID": "week1.html#application",
    "href": "week1.html#application",
    "title": "1  Week 1: Getting started with remote sensing",
    "section": "1.2 Application",
    "text": "1.2 Application\nColour composite image is an important area in remote sensing image application, it is mainly displayed in three primary colours: red, green and blue. By combining different spectral bands (not necessarily visible) to these colours, different features on the ground can be highlighted or distinguished. For example, a false colour composite that uses short-wave infrared, near-infrared and red bands can show vegetation, soil, fire and smoke in different colours.\nIn the image of Issyk-Kul Lake in Kyrgyzstan, scientists used different lights to realize different observation targets.\n\n\n\nImage of Issyk-Kul Lake in Kyrgyzstan. Source: How to Interpret a False-Color Satellite Image\n\n\nThe true color is the composite of red, green and blue.\n\nRed light (620 to 780 nm) can help distinguish between minerals and soils containing high concentrations of iron or iron oxide, making it valuable for studying geology. Because chlorophyll absorbs red light, this band is often used to monitor the growth and health of trees, grasses, shrubs and crops. In addition, red light can help to distinguish between different types of plants over a wide area.\nGreen light (490 to 580 nm) can be used to monitor phytoplankton in the ocean and plants on land. Chlorophyll in these organisms absorbs red and blue light, but reflects green light. Sediments in the water also reflect green light, so a muddy or sandy body of water will look brighter because it reflects both blue and green light\nBlue light (450 to 490 nm) is one of the few wavelengths reflected by water” the rest is absorbed. The blue band is therefore very useful for viewing surface features and spotting the bottom of shallow bodies of water. ou can see that the water reflects some blue light. The water in the blue band is lighter than that in the red or green band, although the lake is too deep for the shallow elements to be seen. Man-made pieces like cities and roads also show up well in blue light. It is also the wavelength at which particles and gas molecules in the atmosphere scatter the most, which is why the sky is blue."
  },
  {
    "objectID": "week1.html#reflection",
    "href": "week1.html#reflection",
    "title": "1  Week 1: Getting started with remote sensing",
    "section": "1.3 Reflection",
    "text": "1.3 Reflection\nWhen material in week1, I used data from Copernicus Open Access Hub. Then, merged the B2 (blue), B3 (green), B4 (red) and B8 (NIR) in R10m with multiband colour, and knew the details in different enhancement options. Then, I learned about difference between R10m and R20m. During the process, I felt interested in several questions and did exploration.\n\n1.3.1 Exploration of nearst neighbour method\nGenerally, upsampling is used to complement the situation when the pixel resolution is greater than the source resolution, and a common interpolation method is nearest neighbour, while downsampling is used when pixel resolution is smaller than source resolution. I felt interested in this method, so I searched for some resources. Here is the mechanism of nearest neighbour:\n\\(X_{src}=X_{dst}*\\frac{Width_{src}}{Width_{dst}}\\)\n\\(Y_{src}=Y_{dst}*\\frac{Height_{src}}{Height_{dst}}\\)\nIf the calculation results in a fractional number, then either remove the decimal part or round up to get the same value as the original dotted pixel. This method is very simple but inaccurate, the zoomed in image has a very bad mosaic and the zoomed out image has a very bad distortion. The problem lies in the treatment of the fractional part, which is equivalent to the process of colour gradation and cannot be fully equated with the existing colour of pixel. It is possible to use bilinear interpolation, considering the four values around the point that needs to be scaled, to see which value has more influence on it, and to give it more weight, I saw the option of bilinear interpolation then tried it. In addition, cubic has more accurate result because non-linear function can fit better but more complex.\n\n\n1.3.2 Explanation of T-test\nWhen learning the code to deal with data from Landsat and Sentinel, I found a final paired t-test is performed to test whether the actual means of the urban land type from Landsat and Sentinel are equal, the degree of freedom from the results is 5970, p-value is much smaller than 0.05, which means the actual means of two groups are quite different, and at the same time, this calculation also shows the estimate mean of two samples. There are 95% probability that the true mean is between -9300.307 and -9198.368. data from Sentinel and Landsat is different.\n\n\n1.3.3 Questions to be explored\nThere are also several areas of interest to me, one of them is how PCA can be used to reduce the dimensionality of data, particularly in image processing, and I will be doing further study and figuring this out. Then, I would like to know if the image data from satellite remote sensing can be used in AI, as there are already mature deep learning algorithms with a high accuracy rate for image recognition, how to use these images to achieve functions such as automatic recognition and automatic monitoring."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2: Portfolio",
    "section": "",
    "text": "Here is the link of presentation which is created via Xaringan:\nPresentation"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "3  Week 3: Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 How does Landsat work to get imagery\nLandsat satellites use scanners to acquire images of the Earth’s surface in different spectral bands.\nLandsat 1-6: use a sensor called the Multispectral Scanner (MSS), which scanned six lines simultaneously in each of the four spectral bands (green, red, near-infrared and mid-infrared) for each mirror sweep. The MSS sensor had a spatial resolution of about 80 meters and covered an area of about 34,000 square kilometers per image.\nLandsat 7 and 8: The MSS sensor was replaced by more advanced sensors on later Landsat satellites, such as the Thematic Mapper (TM), Enhanced Thematic Mapper Plus (ETM+), Operational Land Imager (OLI) and Thermal Infrared Sensor (TIRS), which have higher spatial resolution, more spectral bands and better radiometric accuracy.\n\n\n3.1.2 Geometric correction\nWhy we need geometric corrections:\n\nThe satellite has view angles when watching the Earth\nThe undulating nature of the terrain (topography)\nWind\nRotation of Earth\n\nWorkflow of geometric correction:\n\n\n\nWorkflow. Source: Geometric Correction\n\n\nMethods of geometric correction\n\nsystematic correction the geometry of a lens camera is given by the collinearity equation with calibrated focal length, parameters of lens distortions, coordinates of fiducial marks. The tangent correction for an optical mechanical scanner is a type of system correction.\nNon-systematic correction Polynomials to transform from a geographic coordinate system to an image coordinate system, or vice versa, will be determined with given coordinates of ground control points using the least square method. The accuracy depends on the order of the polynomials, and the number and distribution of ground control points.\n\n\n\n\nNon-systematic correction Source: Geometric Correction\n\n\n\nCombined method Firstly the systematic correction is applied, then the residual errors will be reduced using lower order polynomials. This method is used to obtain accurate images with less error.\n\n\n\n\nCombined method Source: Geometric Correction\n\n\n\n\n3.1.3 Atmospheric correction\nWhy we need atmospheric correction:\n\nReduce the effect from path radiance and the haze created by absorption\nTo calculate the biophysical parameters (e.g. temperature, NDVI)\n\nThe methods to do the atmospheric correction:\n\nDark object subtraction (DOS), search the darkest value of image and subtract that from each pixel\nPsuedo-invariant features (PIFs) use the linear function to adjust the image\nACORN, FLAASH, QUAC, ATCOR\n\n\n\n3.1.4 Orthorectification correction\nWhy we need orthorectification correction:\n\nProvide the coordinates to an image\nRemove the distortions, make pixel viewed at straight down\n\nThe methods to do the orthorectification correction:\n\nConsider the solar zenith angle and solar azimuth angle to do the cosine correction\nThe software we can use QGIS, R packages like RStoolbox\n\n\n\n\nExample of orthorectification correction. Source: calibration from an inclination of 25 degrees to orthographic\n\n\n\n\n3.1.5 Radiometric calibration\nWhy we need radiometric calibration:\n\nConvert the digital number sensors captured from the image brightness (without units) to spectral radiance (with units)\n\nMethods to do the radiometric calibration:\n\nUse converting function"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "3  Week 3: Corrections",
    "section": "3.2 Application",
    "text": "3.2 Application\n\n3.2.1 Image enhancement\nMuhammad Irfan Khan and Muhammad Sharifi compared different remote sensing image enhancement methods based on histogram correction techniques (HE, AGCWD) and transform domain methods (DWT-SVD, ACSEA, RHE-DCT, BF, HIM and SDF). The resulting images were compared visually and quantitatively. It is finally concluded that histogram modification-based methods are better if a higher proportion of detail is present in the image or if the image has a lower resolution, while transform domain methods have better performance for images with a low proportion of detail.\nCompared object 1: \nCompared object 2: \nCompared object 3: \nThe red boxes are the input images for comparison, and the images from b to i correspond to the different image enhancement methods (b: AGCWD, c: DWT-SVD, d: RHE-DCT, e: ACSEA, f: BF, g: HIM, h: SDF, i: BF-HIM)\nVisually, the BF-HIM hybrid method retains colours closer to the reality and enhances edge information better than the previous methods.\nquantitatively, they also give a comprehensive comparison between several methods in 4 indicators, as a result, the hybrid BF-HIM performs better other methods:\n\n\n\nCG value\n\n\n\n\n\nEME value\n\n\n\n\n\nDE value\n\n\n\n\n\nAMBE value"
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "3  Week 3: Corrections",
    "section": "3.3 Reflection",
    "text": "3.3 Reflection\nHere are several interested points after doing pieces of work\n\n3.3.1 DOS and radiance\nI used the remote sensing image (LC08_L1TP_119038_20230104_20230111_02_T1.txt downloaded from USGS EarthExplorer) to calculate the pixel value of surface reflections generated from scattering by DOS:\n\n\n\nl8_boa_ref\n\n\nThere are several methods to execute the atmosphereic corrections (from digital number to reflectance), two typical examples are DOS and converting radiance to reflectance. In this case, the difference between radiance to reflectance and DOS correction is not significant and both can be corrected accurately. Actually, When the atmosphere is thinner or when the weather is good, the influence of the atmosphere on the ground radiation is less, the TOA and BOA are close to each other, a small part of the light reaches the sensor through the path radiance, so the less dark object needs to be substracted, the effect is close to the radiance. On the contrary, the more pixels need to be corrected the more obvious the effect of the corrected image is compared to the pre-correction image.\n\n\n3.3.2 Index calculation\nCalculate the NDVI (Normalized Difference Vegetation Index) in my case.\n\\(NDVI = (Band4 - Band5) / (Band4 + Band5)\\)\n\n\n\nresult of m1_NDVI\n\n\nThe highlight area of healthy vegetation: \nExplanation: from this map, the vegetation in the Taihu Lake basin is more concentrated to the west of the lake, where the most vegetation is found and where there is less population, while the area north of the lake to the south of the Yangtze River is less vegetated due to the high level of urbanisation, while the area north of the Yangtze River is relatively more vegetated.\nCalculate the NDMI (Normalized Difference Moisture Index) Use band 5 and band 6 on the occasion of Landsat8:\n\\(NDMI = (Band5 - Band6) / (Band5 + Band6)\\)\n\n\n\nresult of m1_NDMI\n\n\n\n\n\nresult of moi\n\n\n\n\n3.3.3 PCA\n\n\n\nresult of pca (m1_raster, glcm.red)\n\n\nIt can be seen that in my study area, the component 1 accounts for 54.20%, and the summary of component 1 to component 3 accounts for over 90%, component 1 can explain the 54.2% data from entire dataset."
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "5  week 5: Policy",
    "section": "",
    "text": "6 city plan and application of remote sensing for London"
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "4  Week 4: Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 London City Plan – zero-carbon policy\nWith the increasing scale of greenhouse gas emissions in recent years and the increasing severity of the global warming situation, London 2021 city plan sets a significant goal to minimise the greenhouse gas emission, the detailed aims are below:\n\ncity development should be net-zero carbon: reducing greenhouse gas emission in operation; minimise both annual and peak energy demand according to several energy hierarchies:\n\n\nbe lean: less energy used and energy demand management\nbe clean: fully use local energy (secondary energy explicit) and use energy more efficiently and cleanly.\nbe green: add the opportunity for using renewable energy, provide producing, storing energy on-site\nbe seen: monitor, verify and report on energy performance.\n\n\n\n\nEnergy hierarchy framework. Source: London city plan 2021\n\n\n\nCity development proposals should include energy strategic and demonstrate how energy hierarchy framework includes the zero-carbon target.\nA minimum 35% reduction in energy consumption on site for major development program, 10% for residential developments and 15% for non-residential developments through energy efficiency measures should be achieved. Where this is difficult to achieve, there should be compensation for cash compensation for shortfalls or provide an alternative that will meet the target.\nEach borough government should establish and manage a carbon offset fund, ensure the capital should be invested to the carbon reduction direction, and all the operations should be monitored and reported to specific authorisations.\nCarbon reduction proposal should be quantified as separated to different plants, equipment and other responsible parties.\nWhole life-cycle carbon emissions should be calculated to satisfy the proposal of city development through a nationally recognised Whole Life-Cycle Carbon Assessment."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "5  week4: Policy",
    "section": "5.2 Application",
    "text": "5.2 Application\n\n5.2.1 Case 1: Summer heat spots from Landsat8 Thermal satellite data\nLandsat8 satellite can provide a high-resolution thermal data and use as a basis for mapping the spatial distribution of Great London Area (GLA) surface temperatures and identifying those urban hotspots. This dataset is a count of surface temperatures from the summer months (June, July and August only) between 2016 and 2020, obtained from landsat8 thermal infrared imagery. In addition to the five-year average temperature for the area, the dataset also includes maximum and minimum temperatures and standard deviations to provide a visual representation of the magnitude and range of temperature changes over the five-year period in GLA.\nHigher temperatures tend to occur in densely populated areas.\n\n\n\nheat spot of London summer temperature. Data source: Major Summer Heat Spot London Datastore\n\n\nAs can be seen from the map, the population is predominantly distributed between the north and south banks of the Thames, with the population on the north bank being greater than that on the south bank. The green belt around London can be seen more clearly on the map. The population of the north bank is more dense in the east than in the west. The density of population is high from the City of London all the way north, and is also high in north-east London, decreasing further east. Conversely, the centre of the South Bank is more densely populated, while the east and west are less dense. If Greater London continues to expand, the north-east and south-east would be a better choice.\nTake the City of London for example, some areas saw the highest temperatures compared with the whole city, such as Euston Station east of Regent’s Park, and most of the high heat areas were in high-traffic areas such as train stations, tube stations, shopping malls and airports.\n\n\n\nheat spot in City of London\n\n\nIn addition to population density affecting surface temperatures, industry, airport also have an impact on surface temperatures, with the highest surface temperatures occurring in the five year period shown below at the Dagenham engine plant, ocado customer fullfilment centre, ExCel International Convention and Exhibition Centre along the Thames in east London, and Heathrow Airport to the west.\n\n\n\nHighest temperature areas (east)\n\n\n\n\n\nHighest temperature areas (west)\n\n\nKnowing the temperature changes will help to understand the population distribution in GLA, which in turn will allow transport to be organised to develop faster and more accessible transport in dense areas, to develop infrastructure and to reduce the pressure on existing transport (for example, the central line passes through areas of great population density, and the central line is the oldest tube in London and still the busiest in London). The central line, for example, is the oldest and still the busiest tube in London, so it has to take on a lot of traffic pressure). In addition, more polluting facilities such as factories can be relocated to less populated areas. Knowing the distribution of temperatures can also control the creation of high temperature situations, such as the rare high temperatures in the London area in the summer of 2022.\n\n\n5.2.2 case 2: Remote sensing of motor vehicle emissions in London\nIn response to a call for collaboration between the Mayor of London and the TRUE initiative, carbon emissions from passing vehicles were tested using remote sensing technology at nine sites across Greater London between 2017 and 2018, with carbon emissions data recorded for over 100,000 vehicles, The experiment focused on petrol and diesel vehicles in the London area, with vehicle types including passenger cars, buses, light passenger vehicles, trucks and motorbikes, and measured emissions of carbon oxides and nitrogen oxides.\nThe remote sensing equipment used for the experiments was the Opus AccuScan RSD5000, which was the first to test exhaust gases in three main ways:\n\nThe device emits infrared and ultraviolet light velocities that pass through vehicle emissions, measuring the attenuation of these beams, instant vehicle emissions, the device measures nitrogen oxides and carbon oxides, opacity is measured as a proxy for respirable particulate matter, the device emits a frequency of 200 Hz and can measure 100 times in 0.5 seconds.\nMeasurement of the instantaneous acceleration of the vehicle as a measure of the engine load, which is related to the instantaneous emission rate.\nOne camera is responsible for photographing the vehicle licence plate for database comparison to determine its model, displacement standard.\n\nThe general conditions of testing vehicles\n\n\n\nCharacteristic of testing vehicles. Soruce: Dallmann et al., 2018\n\n\nResult:\n\nDiesel passenger cars are six to seven times more likely to emit nitrogen oxides than petrol passenger cars.\n\n\n\n\n6 standard Euro NOx emission. Source: Dallmann et al., 2018\n\n\n\nEuro5 and Euro6 diesel engines emit significantly more nitrogen oxides than Euro3 and Euro4, while petrol engines emit the similar amount\n\n\n\n\naverage distance NOx emission for different vehicle family. Source: Dallmann et al., 2018\n\n\nTherefore, petrol vehicles outperform diesel vehicles and to achieve carbon emission reductions, the number of diesel vehicles needs to be limited and Euro3 or Euro4 diesel engines should be promoted instead of Euro5 and Euro6."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "4  Week 4: Policy",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nIn this week, I focused on the specific city development goal, minimising carbon emission, building zero-carbon city, to find cases for practice, and use the heat spot distribution map and identification of high-emitted vehicle to demonstrate how these goals are met within the energy hierarchy framework.\nWith the policy and the measurement mentioned on the London city plan 2021, the borough governments will take actions to control high-emitted areas and objects, for example, set the highest emission restriction for plants and equipment, and decrease the peak energy demand. restrict vehicles (time restriction, location restriction) to the city center area, encourage the replacement of Euro engine by providing benefits and making compensation."
  },
  {
    "objectID": "week4.html#application-case-study",
    "href": "week4.html#application-case-study",
    "title": "5  week4: Policy",
    "section": "5.2 Application (case study)",
    "text": "5.2 Application (case study)\nCase 1:"
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week 5: Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Introduction about Google Earth Engine\nGoogle Earth Engine is a cloud-based platform for geospatial data analysis and visualization. It provides access to a vast repository of satellite imagery and geospatial data, as well as a powerful suite of tools for processing and analyzing this data.\nThe advantages of Earth Engine is scalability. The platform can handle extremely large datasets and perform complex analysis in near real-time, making it well suited for monitoring changes on a global scale. Earth Engine also offers an easy-to-use programming interface (use command-based programming, env: javascript), allowing users to write custom scripts and algorithms to perform specific analysis tasks.\nGoogle Earth Engine is also widely used by government agencies, NGOs, and academic institutions for a variety of purposes, including environmental monitoring, natural resource management, and disaster response. The platform is free to use for non-commercial purposes, and access to its data and tools can be granted through a simple application process.\nHere is the link for GEE guidance: https://developers.google.com/earth-engine/guides/objects_methods_overview\n\n\n5.1.2 Objects in GEE\n\nImage: a fundamental raster data type\nImageCollection: a set of images\nGeometry: a fundamental vector data type\nFeature: a geometry with attributes\nFeatureCollection: a set of feature\nReducer: compute statistics or perform aggregations\nJoin: combine databases (images or feature collections) based on keys\nArray: an object for multi-dimensional analyses\nChart: an object for charting properties and spatiotemporal redfuctions\n\n\n\n5.1.3 Architecture of GEE\n\n\n\nArchitecture of GEE Source: Research gate\n\n\nThe manipulation languages for client are JavaScript and Python, and all the requests will be responded by REST API. It has a cluster which contains masters and servers, MapReduce is used to do batch processing job, there are three kinds of databases for storage.\n\n\n5.1.4 Application of Google Earth Engine\nLoad map, point of interest: Changzhou city, Jiangsu Province [31.81, 119.97]\nvar Changzhou = ee.FeatureCollection('users/giscodingmo/gadm41_CHN_2')\n    .filter('NL_NAME_1 == \"常州市\"');\n\nvar oneimage_study_area_cloud = ee.ImageCollection('LANDSAT/LC08/C02/T1_L2')\n.filterDate('2021-01-01', '2022-12-10')\n.filterBounds(Changzhou)  // Intersecting ROI\n.filter(ee.Filter.lt(\"CLOUD_COVER\", 0.1));\n\n\n// load the image\nvar image_120_38 = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_120038_20211004')\n\n// add the image on the map\nMap.addLayer(one_image, {bands: [\"SR_B4\", \"SR_B3\", \"SR_B2\"]}, \"Landsat 8\")\nResult:\n\n\n\npath and row\n\n\n\n\n5.1.5 Discussion of median method\nInitially, I use imageCollection.reduce() function (median method) to reduce the images:\nvar median = oneimage_study_area_cloud.reduce(ee.Reducer.median());\n\n// print the image info\nprint(median, \"median\")\nMedian method is effective when the classification task is between those objects which have giant jump such as forest and non-forest area, water and non-water area.\nIf the gap is not obvious, it is difficult to use median method to integrate images. To improve the accuracy of the classification, an improved method is to add other quartiles to the median, e.g. 25% quartile, 75% quartile. Another method is using seasonal median (spring, summer, fall, winter) to substitute single median, use a curve to fit the trend.\n// example of season medians\nfunction seasonComposite(start) {\n  var end = ee.Number(start).add(2)  \n  // transfer the data type\n  return collection\n  .filter(ee.Filter.calendarRange(start, end, \"month\"))\n  .median()\n}\n\n// call\nvar seasons = ee.List([1,4,7,10]).map(seasonComposite);\nvar composite = ee.ImageCollection(seasons).toBands();\n\n\n5.1.6 Better images\n\n5.1.6.1 True color image\nwrite a function for the surface reflectance rate and temperature adjustment in Landsat Collection 2\n// Applies scaling factors in Collection 2\nfunction applyScaleFactors(image) {\n  var opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2);\n  var thermalBands = image.select('ST_B.*').multiply(0.00341802).add(149.0);\n  return image.addBands(opticalBands, null, true)\n              .addBands(thermalBands, null, true);\n}\n\n// call our collection to the function and assign it to a new variable \nvar oneimage_study_area_cloud_scale = oneimage_study_area_cloud.map(applyScaleFactors);\n\n// apply the median reducer\nvar oneimage_study_area_cloud_scale_median = oneimage_study_area_cloud_scale.reduce(ee.Reducer.median());\n\nprint(oneimage_study_area_cloud_scale_median)\n\n\n// set up some of the visualisation paramters \nvar vis_params = {\n  bands: ['SR_B4_median', 'SR_B3_median', 'SR_B2_median'],\n  min: 0.0,\n  max: 0.3,\n};\n\n// add a layer to the map\nMap.addLayer(oneimage_study_area_cloud_scale_median, vis_params, 'True Color (432)');\nResult:\n\n\n\nvisualization by true color (432)\n\n\n\n\n5.1.6.2 Clip image\nvar clip = meanImage.clip(Changzhou)\n  .select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']);\n\nvar vis_params3 = {\n  bands: ['SR_B4', 'SR_B3', 'SR_B2'],\n  min: 0,\n  max: 0.3,\n};\n\n// map the layer\nMap.addLayer(clip, vis_params3, 'clip');\nResult: the image boundary is followed by city boundary\n\n\n\ncity boundary clip image\n\n\n\n\n\n5.1.7 Texture measures\n// based on the clip generated before\nvar glcm = clip.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7'])\n  .multiply(1000)\n  .toUint16()\n  .glcmTexture({size: 1})\n  .select('SR_.._contrast|SR_.._diss')\n  .addBands(clip);\n  \n// add to the map, but change the range values  \nMap.addLayer(glcm, {min:15, max:650 }, 'glcm');\nResult:\n\n\n\ntexture adjustment\n\n\n\n\n5.1.8 PCA\nPrinciple component analysis code is here:\nvar scale = 30;\nvar bandNames = glcm.bandNames();\n\n// print(bandNames)\n\nvar region = Changzhou.geometry();\n// Map.centerObject(region, 10);\n// Map.addLayer(ee.Image().paint(region, 0, 2), {}, 'Region');\n\n// print(region, \"Changzhou_geometry\")\n// print(bandNames)\n\n// mean center the data and SD strech the princapal components \n// and an SD stretch of the principal components.\nvar meanDict = glcm.reduceRegion({\n    reducer: ee.Reducer.mean(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n});\n\nvar means = ee.Image.constant(meanDict.values(bandNames));\nvar centered = glcm.subtract(means);\n\n\n// This helper function returns a list of new band names.\nvar getNewBandNames = function(prefix) {\n  var seq = ee.List.sequence(1, bandNames.length());\n  return seq.map(function(b) {\n    return ee.String(prefix).cat(ee.Number(b).int());\n  });\n};\n\n\n// This function accepts mean centered imagery, a scale and\n// a region in which to perform the analysis.  It returns the\n// Principal Components (PC) in the region as a new image.\nvar getPrincipalComponents = function(centered, scale, region) {\n  // Collapse the bands of the image into a 1D array per pixel.\n  var arrays = centered.toArray();\n\n  // Compute the covariance of the bands within the region.\n  var covar = arrays.reduceRegion({\n    reducer: ee.Reducer.centeredCovariance(),\n    geometry: region,\n    scale: scale,\n    maxPixels: 1e9\n  });\n\n  // Get the 'array' covariance result and cast to an array.\n  // This represents the band-to-band covariance within the region.\n  var covarArray = ee.Array(covar.get('array'));\n\n  // Perform an eigen analysis and slice apart the values and vectors.\n  var eigens = covarArray.eigen();\n\n  // This is a P-length vector of Eigenvalues.\n  var eigenValues = eigens.slice(1, 0, 1);\n  // This is a PxP matrix with eigenvectors in rows.\n  \n  var eigenValuesList = eigenValues.toList().flatten()\n  var total = eigenValuesList.reduce(ee.Reducer.sum())\n  var percentageVariance = eigenValuesList.map(function(item) {\n  return (ee.Number(item).divide(total)).multiply(100).format('%.2f')\n    })\n  \n  print(\"percentageVariance\", percentageVariance)  \n\n  var eigenVectors = eigens.slice(1, 1);\n\n  // Convert the array image to 2D arrays for matrix computations.\n  var arrayImage = arrays.toArray(1);\n\n  // Left multiply the image array by the matrix of eigenvectors.\n  var principalComponents = ee.Image(eigenVectors).matrixMultiply(arrayImage);\n\n  // Turn the square roots of the Eigenvalues into a P-band image.\n  var sdImage = ee.Image(eigenValues.sqrt())\n    .arrayProject([0]).arrayFlatten([getNewBandNames('sd')]);\n\n  // Turn the PCs into a P-band image, normalized by SD.\n  return principalComponents\n    // Throw out an an unneeded dimension, [[]] -> [].\n    .arrayProject([0])\n    // Make the one band array image a multi-band image, [] -> image.\n    .arrayFlatten([getNewBandNames('pc')])\n    // Normalize the PCs by their SDs.\n    .divide(sdImage);\n};\n\n// Get the PCs at the specified scale and in the specified region\nvar pcImage = getPrincipalComponents(centered, scale, region);\n\n// Plot each PC as a new layer\nfor (var i = 0; i < bandNames.length().getInfo(); i++) {\n  var band = pcImage.bandNames().get(i).getInfo();\n  Map.addLayer(pcImage.select([band]), {min: -2, max: 2}, band);\n}\nResult: I got the pictures, the number is equal to the length of bandNames, in my case, the bandNames contains 21 elements.\n\n\n\nexample of PCA analysis\n\n\nThe first component can explain 63.68% of variance within the collection and the second component explains 26.66%, the third explains only 6.11%, therefore, I can just add pc1 and pc2 instead of the entire image, somethimes, pc3 can also be added to improve the accuracy, reaching 96.45%.\n\n\n\nPercentage variables of PCA\n\n\nMap.addLayer(pcImage, {bands: ['pca3', 'pc2', 'pc1'], min: -2, max: 2}, 'PCA bands 1, 2 and 3');\n\nMap.addLayer(pcImage, {bands: ['pc2', 'pc1'], min: -2, max: 2}, 'PCA bands 1, 2');\nComparison between 2 components and 3 components:\n\n\n\n2 components\n\n\n\n\n\n3 components\n\n\nExport image to drive\nvar PCA_out = pcImage.select(['pc1', 'pc2', 'pc3'])\n\nvar projection = PCA_out.select('pc1').projection().getInfo();\n\nvar bounds = Changzhou.geometry();\n\n// Export the image, specifying the CRS, transform, and region.\nExport.image.toDrive({\n  image: PCA_out,\n  description: 'PCA_Changzhou',\n  scale:30,\n  crs: projection.crs,\n  maxPixels: 100E10,\n  region: bounds\n});\n\n\n5.1.9 Band math (NDVI)\nCalculate the NDVI quickly, use blue to identify the water area, green to identify the forest or vegetation area and white to identify the town, city\n//NDVI\nvar NDVI_1 = clip.select('SR_B5').subtract(clip.select('SR_B4'))\n  .divide(clip.select('SR_5').add(clip.select('SR_B4')));\n\nMap.addLayer(NDVI_1, { min: -1, max: 1, palette: ['blue', 'white', 'green']}, 'NDVI');\n\n\n\nNDVI"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "5  Week 5: Google Earth Engine",
    "section": "5.2 Application",
    "text": "5.2 Application\n\n5.2.1 Monitoring of wetlands\nMahdianpari et al. assessed 30 years of change in Newfoundland wetlands using Landsat imagery, spectral indices and random forest classification within the Google Earth Engine (GEE) cloud computing platform.\nOverall accuracy was high, ranging from 84.37% to 88.96%. In a comparison of different classifiers, random forest produced the highest accuracy results and allowed for the estimation of variable importance when comparing classification to regression trees (CART) and minimum distances (MD).\nThe most important variables included thermal infrared (TIR), elevation, difference vegetation index (DVI), shortwave infrared (SWIR) and normalised difference vegetation index (NDVI). The change detection analysis showed that bog, marsh and swamp were the most common wetland categories for all time periods and that boggy wetlands were the most common wetland type for all time periods. The analysis also revealed a general instability of wetland categories, although this was mainly due to transitions from one wetland category to another.\n\n\n\nGeneral research methods of study. Source: A large-scale change monitoring of wetlands using time series Landsat imagery on Google Earth Engine\n\n\nThe result of different land cover classification \n\n\n5.2.2 Forest cover change\nHansen et al. (2013) studied the change of forest cover in global area. The studied published in 2013 that used satellite data to map global forest loss and gain from 2000 to 2012123. The paper reported that the tropics had the highest forest loss and the lowest forest gain, while subtropical forests had the highest rates of forest change due to intensive forestry.\n\n\n\nGlobal forest cover change. SourceHigh-Resolution Global Maps of 21st-Century Forest Cover Change\n\n\n\n\n\n4 typical area forest gain and loss. SourceHigh-Resolution Global Maps of 21st-Century Forest Cover Change"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "5  Week 5: Google Earth Engine",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nIn this week, I learned knowledge in several aspects: how to use Google Earth Engine to create points and analyse the ROI assisted with GADM boundary map.\n\nunderstood the advantages and disadvantages of using median methods to get the reduced images (advantages: fast calculation, be suitable for those objects which has giant difference; disadvantages: not accurate, can not reflect the trend of change) and knew the alternative and more accurate methods (multiple quantile methods: using 10% quantile, 25% quantile, 75% quantile, seasonal medians methods: using four medians to represent 4 seasons)\ncreate true color image, mosaic image, clip image and do the texture adjustment by glcm\nprinciple component analysis and find the explainable percentage, calculated NDVI and export them to local"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "CASA0023 Learning Diary",
    "section": "0.1 Introduction",
    "text": "0.1 Introduction\nWelcome to my learning diary"
  },
  {
    "objectID": "week4.html#application-on-carbon-emission",
    "href": "week4.html#application-on-carbon-emission",
    "title": "4  Week 4: Policy",
    "section": "4.2 Application on carbon emission",
    "text": "4.2 Application on carbon emission\n\n4.2.1 Step 1: Heat spots identification\nLandsat8 satellite can provide a high-resolution thermal data and use as a basis for mapping the spatial distribution of Great London Area (GLA) surface temperatures and identifying those urban hotspots.\n\nDataset description:\n\nThis dataset is a count of surface temperatures from the summer months (June, July and August only) between 2016 and 2020, obtained from landsat8 thermal infrared imagery. In addition to the five-year average temperature for the area, the dataset also includes maximum and minimum temperatures and standard deviations to provide a visual representation of the magnitude and range of temperature changes over the five-year period in GLA.\n\nDistribution map and analysis\n\nHigher temperatures indicate places with high population density or dense plant and equipment, where greenhouse gas emissions are generally higher than in places with less.\n\n\n\nheat spot of London summer temperature. Data source: Major Summer Heat Spot London Datastore\n\n\nAs can be seen from the map, the population is predominantly distributed between the north and south banks of the Thames, with the population on the north bank being greater than that on the south bank. The green belt around London can be seen more clearly on the map. The population of the north bank is more dense in the east than in the west. The density of population is high from the City of London all the way north, and is also high in north-east London, decreasing further east. Conversely, the centre of the South Bank is more densely populated, while the east and west are less dense. If Greater London continues to expand, the north-east and south-east would be a better choice.\nTake the City of London for example, some areas saw the highest temperatures compared with the whole city, such as Euston Station east of Regent’s Park, and most of the high heat areas were in high-traffic areas such as train stations, tube stations, shopping malls and airports.\n\n\n\nheat spot in City of London\n\n\nIn addition to population density affecting surface temperatures, industry, airport also have an impact on surface temperatures, with the highest surface temperatures occurring in the five year period shown below at the Dagenham engine plant, ocado customer fullfilment centre, ExCel International Convention and Exhibition Centre along the Thames in east London, and Heathrow Airport to the west.\n\n\n\nHighest temperature areas (east)\n\n\n\n\n\nHighest temperature areas (west)\n\n\nKnowing the temperature changes will help to understand the population distribution in GLA, which in turn will allow transport to be organised to develop faster and more accessible transport in dense areas, to develop infrastructure and to reduce the pressure on existing transport (for example, the central line passes through areas of great population density, and the central line is the oldest tube in London and still the busiest in London). The central line, for example, is the oldest and still the busiest tube in London, so it has to take on a lot of traffic pressure). In addition, more polluting facilities such as factories can be relocated to less populated areas. Knowing the distribution of temperatures can also control the creation of high temperature situations, such as the rare high temperatures in the London area in the summer of 2022.\n\n\n4.2.2 Step 2: Identification of high-emitted vehicles\nIn response to a call for collaboration between the Mayor of London and the TRUE initiative, carbon emissions from passing vehicles were tested using remote sensing technology at nine sites across Greater London between 2017 and 2018, with carbon emissions data recorded for over 100,000 vehicles, The experiment focused on petrol and diesel vehicles in the London area, with vehicle types including passenger cars, buses, light passenger vehicles, trucks and motorbikes, and measured emissions of carbon oxides and nitrogen oxides.\n\nDataset example\n\n\n\n\ndata descriptive statistics. Soruce: Dallmann et al., 2018\n\n\n\nRemote sensing equipment introduction\n\nThe remote sensing equipment used for the experiments was the Opus AccuScan RSD5000, which was the first to test exhaust gases in three main ways:\n\nThe device emits infrared and ultraviolet light velocities that pass through vehicle emissions, measuring the attenuation of these beams, instant vehicle emissions, the device measures nitrogen oxides and carbon oxides, opacity is measured as a proxy for respirable particulate matter, the device emits a frequency of 200 Hz and can measure 100 times in 0.5 seconds.\nMeasurement of the instantaneous acceleration of the vehicle as a measure of the engine load, which is related to the instantaneous emission rate.\nOne camera is responsible for photographing the vehicle licence plate for database comparison to determine its model, displacement standard.\n\n\n\n\nremote sensing equipment\n\n\n\nThe general conditions of testing vehicles\n\n\n\n\nCharacteristic of testing vehicles. Soruce: Dallmann et al., 2018\n\n\n\nResult:\n\n\nDiesel passenger cars are six to seven times more likely to emit nitrogen oxides than petrol passenger cars.\n\n\n\n\n6 standard Euro NOx emission. Source: Dallmann et al., 2018\n\n\n\nEuro5 and Euro6 diesel engines emit significantly more nitrogen oxides than Euro3 and Euro4, while petrol engines emit the similar amount\n\n\n\n\naverage distance NOx emission for different vehicle family. Source: Dallmann et al., 2018\n\n\nTherefore, petrol vehicles outperform diesel vehicles and to achieve carbon emission reductions, the number of diesel vehicles needs to be limited and Euro3 or Euro4 diesel engines should be promoted instead of Euro5 and Euro6."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "6  Week 6: Classification I",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nThis week I learned how to build a model to solve classification problem.\n\n6.1.1 Machine learning in remote sensing\n\nsupervised learning:\n\nregression problem:\n\nregression tree\nsupport vector regression\n\nclassification problem\n\ndecision tree\nrandom forest\nboosting and Xgboost\n\n\nunsupervised learning:\n\nclustering: K-means and GMM\n\n\n\n6.1.1.1 Decision tree\nThe algorithm works by recursively partitioning the feature space into smaller regions using a series of binary splits. At each split, the algorithm selects the feature that best separates the data into the target classes or predicts the target variable. The split is made based on the value of the selected feature, and the data is split into two or more subgroups based on the selected threshold value. This process is repeated until a stopping criterion is met, such as a minimum number of observations in a subgroup, or no further improvement in the classification or regression accuracy.\n\n\n\nMechanism of decision tree. Source: JavaTPoint\n\n\nClassification algorithm and Regression Tree (CART) is a typical algorithm to calculate the entropy when each branch generates. the classic function is gini index.\n\\(Entropy(s)= -P(yes)log2 P(yes)- P(no) log2 P(no)\\)\n\\(Gini Index= 1- ∑^{j}_{j=0}P_j^2\\)\nTo visualize a decision tree, we can use graphviz, this tool can convert .dot file (describe area of root, node) into graph. Here, in this case, when entropy is equal to 0, the tree has one leaf.\n\n\n\nAn example of decision tree visualized by Graphviz\n\n\n\n\n6.1.1.2 Random forest\nRandom forest is an ensemble learning method that combines multiple decision trees to make more accurate predictions.\nThe random forest algorithm works by constructing multiple decision trees during training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. Each tree is constructed using a random subset of the training data and a random subset of the features. This helps to prevent overfitting and reduces variance in the predictions.\nFirst step is how do use limited dataset to generate different inputs of each decision tree, this process is called bootstrap sampling. the algorithm will compare the mean and standard deviation of each sampling data to ensure they are not the same sampling data.\n\n\n\nBootstrap sampling\n\n\nThen, the sampling data will be input into different decision tree, finally, the output may be the average value of result or a majority voting mechanism.\n\n\n\nFlow of random forest\n\n\nThere are also some potential drawbacks of the random forest algorithm, which includes its computational complexity and its tendency to perform poorly on datasets with imbalanced classes. However, with proper tuning and optimization, these limitations can be overcome.\n\n\n6.1.1.3 Xgboost\nBefore introducing Xgboost it is boosting, both boosting and random forests are essemble learning algorithms that use multiple decision trees. When processing the output of multiple decision trees, boosting calculates the residuals of each tree and minimizes them by constructing a loss function for the residuals to obtain the optimal solution.\n\n\n\nMechanism of Xgboost\n\n\nThen, how to get the minimum value of loss function, Xgboost uses gradient boosting machine (GBM) and make improvement.\n\n\n\nBenefits of Xgboost\n\n\nIn general, the relationship between the algorithms below:\n\n\n\nRelationship\n\n\n\n\n\n6.1.2 GEE classification\nThis is a workflow of my training, testing and validation process, I use Lhasa city, Tibet as point of interests.\n\n\n\nWorkflow\n\n\n\n6.1.2.1 Training\nI selected several typical land types in Lhasa city because the accuracy of model depends on the accuracy of labels, so the classification of the various different land types had to be accurate in order for the resulting model to work better.\n\nurban area: (with high density) one community of Lhasa city center, Lhasa financial center, universities\nwater: the Namucuo in northern Lhasa, Lhasa river\nwetland: Lalu Wetland National Nature Reserve (sample many times)\nbare earth: Zayaba Monastery, mountain area\nforest: Lhasa Nimu National Forest Park,\nice land: the top of those mountains\nurban area: (with low density) living area, villages around the city center\n\n\n\n6.1.2.2 Testing\n\nExample 1\n\n\n\n\nLhasa city center classification\n\n\nAs the picture shows, this is the centre of Lhasa, the red coloured part is the Lhasa River flowing through the city, the blue is the main city with a high population density, while the white part in the upper left corner is a larger wetland, the periphery of the city centre is bare ground.\n\nExample 2\n\n\n\n\nNamucuo and mountain\n\n\nIn this example, the red part represents the water part and the blue part is the mountain peak and is above 6,000m, therefore the peaks are covered in snow all year round. Comparing this with the map, I found that the area is the Nyingchi Tanggula range, where you can see that the ridges run from north-east to south-west, and the green parts are mixed coniferous forests, located on the mountainsides and at the foot of the mountains. The thin blue line in the bottom right corner is the Qinghai-Tibet Highway, which runs along the Nyingchi Tanggula Range.\nHowever, this method depends on the accuracy of the training data I selected before, I introduced another more accurate method.\n\n\n6.1.2.3 Adjustment\nInitially with 7 categories, I found the accuracy of the validation dataset to be around 80% and the OOB error to be around 17%, independent of both how many datasets were divided into training sets and how many trees were used in random forest. I realized it is possible to reduce the categories.\nWhen combining urban_high and urban_low, I saw a significant increase in those indicators, based on this finding, I then combine the forest and wetland land types, and compare the indicators with ice land and without ice land.\n\nout of bag error estimate: 7.56%\nTraining overall accuracy: 98.91%\nValidation overall accuracy: 92.38%\n\n\n\n\n4 categories\n\n\n\n\n\nLhasa city center under 4 categories\n\n\nThe results show that the indicators divided into four categories are better than the five categories. although 3 categories performs better than 4 categories, urban features and river features are not well identified and therefore 3 categories are not used.\n\nurban area\nwater area\nbare earth\nwetland\n\nIt is true that increasing the number of trees in a decision tree can help to improve accuracy, and increasing from 100 to 300 trees can improve metrics such as accuracy, but after increasing to 500 trees there is no significant change."
  },
  {
    "objectID": "week6.html#application",
    "href": "week6.html#application",
    "title": "6  Week 6: Classification I",
    "section": "6.2 Application",
    "text": "6.2 Application\n\nTehran Province study\n\nNasiri et al. (2020) used the Google Earth Engine (GEE) cloud computing platform to create cloud-free Sentinel-2 and Landsat-8 time series for Tehran Province (Iran) up to 2020 and to find out how the two synthetic methods and the spectro-temporal metrics extracted from the satellite time series affect the machine learning classifier ability to generate accurate LULC maps. They used two synthetic methods, seasonal composites and percentile indicators, for defining four datasets based on satellite time series, vegetation indices and topographic layers. A random forest classifier was used for Land Use and Land Cover (LULC) classification and to identify the most important variables. Accuracy assessments showed that Sentinel2 outperformed the Landsat8 spectral time metrics at the overall and category level.\n\n\n\nWorkflow of study\n\n\n\n\n\nLULC maps resulting from the four datasets based on the S-2 and L-8 spectral–temporal metrics. Source: Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images\n\n\nBoth S-2 and L-8 show phenological variation in the LULC categories, particularly on agricultural land and woodland, is effectively provided by seasonal composites.\n\n\n\nSpring, summer and autumn compasison between L-8 and S-2 R:(NIR), G:Green, B:Blue\n\n\nThis picture is a comparison between S-2 and L-8 to distinguish different land cover between bare and artificial land, grassland and harvested farmland. It can be shown that boundary of different land types S-2 identified is better than L-8.\n\n\n\nD-1, D-2 is Sentinel2 seasonal composites and percentile metrics, while D-3, D-4 is Landsat 8\n\n\nThe study concluded that the MODIS time series and the extracted spectro-temporal metrics are a reliable source of accurate LULC mapping. However, some differences between datasets were observed. For example, the LULC maps generated from the S-2 time series were more accurate than those generated from the L-8 time series. Comparisons between the combination methods showed that the seasonal median combination outperformed the percentile index in both the S-2 and L-8 time series. The results demonstrate the validity of the vegetation indices, particularly NDVI and NDBI, and the S-2 red border, with respect to the importance of the variables."
  },
  {
    "objectID": "week6.html#reflection",
    "href": "week6.html#reflection",
    "title": "6  Week 6: Classification I",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nIn this week, I know how to select my own ROI, process graphics and classify different land type based on decision tree and random forest.\nThere are several problems I found in process:\nHyperparameter tuning was crucial when training the classifier, as I couldn’t decide exactly how many decision trees I needed to make the classifier work well when training the model, and I kept trying to manually tune it throughout the process, and should probably try looking for hyperparameters, such as grid search.\nIn practice, I found that if I defined too many types, the accuracy of the test set was consistently below 90% and the out-of-bag error was above 10%. Although the training set performed well, this suggested that I had too many categories, which led to underfitting, and I merged some categories to improve the accuracy of the test set and reduce the out-of-bag error y. I am not sure if this is a good idea. I’m not quite sure if this is reasonable"
  },
  {
    "objectID": "index.html#background-information",
    "href": "index.html#background-information",
    "title": "CASA0023 Learning Diary",
    "section": "Background information",
    "text": "Background information\nMy name is Wenxi Mo, my bachelor’s degree is Electrical and Electronic Engineering in Cardiff University, master’s degree is Social and Geographic Data Science in UCL. In my spare time I enjoy different sports: basketball, football, running and so on. I hope to learn skills in this module that will help me in the future."
  },
  {
    "objectID": "index.html#information-about-this-learning-diary",
    "href": "index.html#information-about-this-learning-diary",
    "title": "CASA0023 Learning Diary",
    "section": "0.3 Information about this learning diary",
    "text": "0.3 Information about this learning diary\nThis book is a learning diary for CASA0023 Remotely Sensing Cities and Environments, master course of UCL, the content of this course includes the principle of remote sensing, applications, and analysis using several tools, R and Google Earth Engine. This book is written by Quarto Book, all the code can be seen on my github page.\n\n\n\nWhat is Remote Sensing"
  },
  {
    "objectID": "index.html#about-this-learning-diary",
    "href": "index.html#about-this-learning-diary",
    "title": "CASA0023 Learning Diary",
    "section": "About this learning diary",
    "text": "About this learning diary\nThis book is a learning diary for CASA0023 Remotely Sensing Cities and Environments, master course of UCL, the content of this course includes the principle of remote sensing, applications, and analysis using several tools, R and Google Earth Engine. This book is written by Quarto Book, all the code can be seen on my github page.\n\n\n\nWhat is Remote Sensing"
  },
  {
    "objectID": "week3.html#section",
    "href": "week3.html#section",
    "title": "4  Week 3: Corrections",
    "section": "4.4 ",
    "text": "4.4 \nIn this week, I learned the knowledge about the corrections, and the methods about corrections, the distortion of the images from remote sensing is mainly due to the presence of sensor observations in terms of declination, topography, wind and so on. Their correction uses statistical knowledge and principles (such as PCA, linear regression) as well as knowledge of spatial geometry.\nI think it is useful for the further study and work, for example, correcting the satellite image to satisfy people’s demand."
  },
  {
    "objectID": "week8.html#summary",
    "href": "week8.html#summary",
    "title": "8  Week8: Temperature",
    "section": "8.1 Summary",
    "text": "8.1 Summary\n\n8.1.1 Urban Heat Island problem\n\n8.1.1.1 Definition\nUrban heat island is a city that is much warmer than its surrounding rural areas because of human activities. The temperature difference can be up to 7°F during the daytime\n\n\n\nDescription of Urban Heat Island\n\n\nExample of London: in this graph, it can be seen that the closer to the city center the hotter the area is, as there are more sources of heat and the temperature decreases from the center to the periphery, a typical heat island effect.\n\n\n\nUHI in London. Source: London Climate Change\n\n\n\n\n8.1.1.2 Hazards of UHI\nAffected population: from the investigation within 13,115 cities from 1983 to 2016, urban exposure increased nearly 200%, affecting 1.7 billion people.\nEconomic loss: In Melbourne, for example, if the heat island effect is not controlled, the city’s economic losses will increase every year, and this increase is mainly in terms of the impact on human health and energy use, with the heat island effect threatening health and therefore necessitating greater investment in healthcare resources, and energy consumption mainly in terms of cooling\n\n\n\nEconomic loss in Melnourne. Source: AECOM, 2012\n\n\nEnvironment impact: urban heat island (UHI) raises electricity demand during summer. As a result, power plants have to supply the needed extra energy, and since they rely on fossil fuel for energy production, there is an increase in greenhouse gas emissions and air pollutants. The main greenhouse gases and pollutants include carbon monoxide (CO), carbon dioxide (CO2), sulfur dioxide (SO2), nitrogen oxides (NOx), particulate matter and Mercury (Hg). Increased greenhouse gases cause global warming and climate change.\n\n\n8.1.1.3 Policies\n\nGlobal\n\nNew Urban Agenda = standards and principles for planning, construction, development, management and urban improvement\n\nPoint 54\n\nWe commit ourselves to the generation and use of renewable and affordable energy and sustainable and efficient transport infrastructure and services, where possible, achieving the benefits of connectivity and reducing the financial, environmental and public health costs of inefficient mobility, congestion, air pollution, urban heat island effects and noise.\n\nPoint 79\n\nWe commit ourselves to promoting international, national, subnational and local climate action, including climate change adaptation and mitigation, and to supporting the efforts of cities and human settlements, their inhabitants and all local stakeholders as important implementers.\n\nPoint 37\n\nWe commit ourselves to promoting safe, inclusive, accessible, green and quality public spaces, including streets, sidewalks and cycling lanes, squares, waterfront areas, gardens and parks, that are multifunctional areas for social interaction and inclusion, human health and well-being\n\nlocal\n\n\nSingapore\n\n\nIntroduce more efficient physical infrastructure, such as district-level cooling that efficiently uses energy to mechanically cool large areas in cities\nNature-based solutions, such as increasing the extent and density of green spaces in cities and on walls and roofs, and;\nIntegrated, inclusive planning of urban stakeholders to ensure that vulnerable urban residents are protected\nuse substituted cooling solution, propane as a refrigerant could lessen the global temperature increase from space cooling, meaning that we could avoid a 0.09°C increase in global temperature by the end of the century, making a significant contribution toward keeping the global temperature rise below 1.5 °C.\n\n\n\n\nPropane cooling solution. Source: World Economic Forum\n\n\n\nMedellín’s interconnected green corridors\n\nSince 2016, Medellín has created 30 ‘Corredores Verdes,’ an interconnected network of greenery across the city, it demonstrates how integrated, nature-based policies like widespread urban tree planting can have a far-reaching impact on the local and global environment, as well as significantly improving citizens’ lives and well-being.\n\n\n\nGreen corridors. Source: Arch diary\n\n\n\nCooling Cities with Zoning in Cambridge, Massachusetts\n\nAt the city level, cities are continuing early work described in Scorched to develop heat-informed zoning policies. Cambridge estimated the temperature-reduction effects of various cooling strategies—such as preserving mature trees and using light-colored paving and building materials—and drafted a site scoring system that is now being piloted at four sites.\n\n\n\nZoning policy. Source: URBANLAND\n\n\n\n\n\n8.1.2 Application in GEE\nTo analyze the temperature distribution and urban heat island effect, I use Houston city, USA as an example\n\n\n\nLandsat temperature map\n\n\n\n\n\nMean summer temperature image\n\n\nIt is shown in this picture, the center area of Houston has higher temperature, and Low temperature appears from north-east part south-east part of Houston, this part is mountain and sea, west area seems to be hotter than east area.\n The highest temperature in summer appears around 20 June, and the lowest temperature appears in 15-20 September, average temperature in summer is higher than 30 degree."
  },
  {
    "objectID": "week8.html#applicaion",
    "href": "week8.html#applicaion",
    "title": "8  Week8: Temperature",
    "section": "8.2 Applicaion",
    "text": "8.2 Applicaion\n\nCase 1: socioeconomic drivers of urban heat island effect\n\nLi et al. (2020) tried to measure the magnitudes and marginal effect of socioeconomic drivers on UHI dynamics in major Chinese cities. Generalized additive model (GAM) sre used for modelling non-linear/linear relations between economic output, population, industrial structure, geographical features and UHI at seasonal and climate-zones level.\nThe result shows that socioeconomic factors explain 12 %∼20 % of UHI intensity variations. Urban economic scale generally has a higher contribution rate than variables of population and industrial structure. Urban economic growth raised the heat stress in hot summer. Moreover, a negative linear nexus was observed between the UHI intensity and per capital GDP, indicating that the empirical results supported a post-environmental Kuznets curve (EKC) relationship during the sample period.\nVariables selected according to this correlation coefficient matrix\n\n\n\nSource: Li et al. (2020)\n\n\ngeneralized additive model expression formula:\n \nThe result shows the annual UHII increased rapidly until 2010 and remained stable after 2010. Significant seasonal variations in UHII were also observed during the study period. The mean LST was greater in summer than in winter for both urban and rural differences. In summer, mean UHII initially increases and then decreases after 2010. The winter response curve showed a U-shaped trajectory.\nThis is an application of generalized additive model in different seasons, the solid black line indicates the trend in UHII with the year of observation, and the shaded area centered on the solid line indicates the lower and upper limits of UHII.\n\n\n\nApplication of GAM\n\n\n\nCase 2: global urban population exposure to extreme heat\n\nTuholske et al. (2021) examines how urbanization affects the exposure of human populations to extreme heat events. They use satellite data and climate models to estimate the urban heat island (UHI) effect and the population density for 1692 cities around the world. They find that urbanization increases both the frequency and intensity of extreme heat events, especially in tropical regions. Based on this, they predict that by 2050, more than 1.6 billion people in urban areas will experience at least 20 days per year with a maximum temperature above 35 °C, which is a fourfold increase from 2000. Therefore, they suggest that urban planning and design strategies can help mitigate the UHI effect and reduce the risk of heat-related mortality and morbidity.\nThey found a linear relationship between overall population growth and the increase in the urban heat island effect over the years, which has led to an increasing number of people being exposed to the adverse effects of the heat island effect.\n\n\n\nLinear relationship. Soruce: Tuholske et al. (2021)\n\n\nThis is a global map of the increase in the number of people at risk from the heat island effect, which shows that the number of people affected per day is significant in western Africa near the equator, eastern Africa, all of India and southeastern China, Southeast Asia, Central America and the Middle East, and also shows that the heat island effect is increasing significantly in these areas.\n\n\n\nGlobal map of UHI exposed population\n\n\nThe following regions are typical of the major population growth areas of recent times, the most significant cause of temperature growth in South Asia and Saharan Africa is population growth and consequently, heat island effect, and a relatively small share of global warming, typical city is Kolkata in India. West Asia and the Latin American Caribbean are evenly divided, but population growth is an important factor that cannot be ignored.\n\n\n\nReason for temperature increase (four regions)"
  },
  {
    "objectID": "week8.html#reflection",
    "href": "week8.html#reflection",
    "title": "8  Week8: Temperature",
    "section": "8.3 Reflection",
    "text": "8.3 Reflection\nThe urban heat island effect is a key concern for city managers at the moment, and it can be seen that many cities have introduced policies to combat the heat island effect and reduce urban temperatures.\nThe point that I am more interested in is how to do a temperature simulation of a city using the SOLWEIG model and collect the input values needed for this model. This link (https://umep-docs.readthedocs.io/projects/tutorial/en/latest/Tutorials/IntroductionToSolweig.html) is an introduction to the model and its applications, which I would like to explore outside of this course, not only for my future projects of the same type, but also to enhance my coding and graphical skills.\n\n\n\nSOLWEIG model workflow"
  },
  {
    "objectID": "week7.html#summary",
    "href": "week7.html#summary",
    "title": "7  Week7: Classification II",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week I learned several analysis methods, object based image analysis and sub pixel analysis\n\n7.1.1 Objected based image analysis\nSuperpixels are regions of pixels that have similar values and can be used to simplify image processing tasks such as segmentation. It is common to use SLIC algorithm is a method to generate superpixels by clustering pixels in a five-dimensional color and image plane space. It is fast, easy to use and produces compact and uniform superpixels.\nThe top-left panel shows the initial segmentation. The top-right and bottom-left show the segmentation after 1 and 10 iterations. SLIC has converged in the bottom-right panel\n\n\n\nA simple case of SLIC algorithm. Source: Researchgate\n\n\n\nThe improvement of SLIC algorithm - SLICO\n\nSLIC need to set the compactness parameter or try different values of it, but SLICO adaptively chooses the compactness parameter for each superpixel differently. This generates regular shaped superpixels in both textured and non textured regions alike.\n\n\n\nComparison between SLIC (up) and SLICO (down). Source: EPFL\n\n\n\n\n7.1.2 Subpixel analysis\nSubpixel analysis can estimate the location or movement of an object in an image with a precision higher than the pixel level1. subpixel analysis can be used to measure the dimensions of a small object by removing the background spectra and comparing the residual spectrum with a signature spectrum\n\n\n\nSubpixel mapping. Source: Researchgate\n\n\n\n\n7.1.3 Accuracy assessment\nHere we use the confusion matrix to assess the accuracy of algorithm performance, but not every indicator can be satisfied because of the conflict of indicators themselves.\n\n\n\nConfusion matrix. Source: Barsi et al. 2018 Accuracy Dimensions in Remote Sensing\n\n\n\nproducer’s accuracy defined as the fraction of correctly classified pixels (TP) compared to ground truth data (TP+FN)\n\n\\(TP / (TP + FN)\\)\n\nuser’s accuracy defined as the fraction of correctly classified pixels (TP) relative to all others classified as a particular land cover(TP+FP)\n\n\\(TP / (TP + FP)\\)\n\noverall accuracy that represents the combined fraction of correctly classified pixels (TP +TN) across all land cover types (TP+FP+FN+TN)\n\n\\((TP +TN) / (TP + FP + FN + TN)\\)\n\n7.1.3.1 F1 score\nThe F1-Score (or F Measure) combines both recall (Producer accuracy) and Precision (User accuracy), the importance of F1 score is that it can balance the trade-off between precision and recall, and give more weight to both false positives and false negatives than accuracy alone.\n\n\n\nF1 formula\n\n\n\n\n\nSource: mlu-explain\n\n\n\n\n7.1.3.2 ROC curve\nROC curve is a useful tool to measure the generalization ability of a machine learning algorithm, but in reality, we can get the right curve (discrete) based on limited cases and extrapolate the complete curve\n\n\n\nROC and AUC. Source: Machine learning\n\n\n\n\n7.1.3.3 Cross validation\nIn order to enhance the randomness of training data, it is common to use cross validation, here is the schematic diagram.\n\n\n\nCross validation\n\n\n\n\n7.1.3.4 Spatial cross validation\nSpatial cross validation splits the data into groups based on their spatial coordinates, and then evaluates a model on each group separately. It is used to avoid overfitting or underfitting when the data has spatial structure or dependence.\n\n\n\nSpatial visualization of traing data and testing data. Source: Lovelace et al. 2020\n\n\n\n\n7.1.3.5 GEE practice\nI used several classification methods mentioned before and used Lhasa Tibet as an analysis example.\nHere is the workflow:\n\nselect Lhasa vector data and EO data\nsub-pixel analysis use unmix() to add all togther and calculate confusion matrix\nobject based image analysis, use gradient()\nsuperpixel analysis, use k-means then set seeds, run SNIC and calculate NDVI, do a classification task.\n\nHere is the result of each method:\n\n\n\nSub-pixel\n\n\n\n\n\nObject\n\n\n\n\n\nSuper-pixel\n\n\nIn general, sub-pixel shows more detailed information than superpixel, the differentiation between small pixels is ignored, resulting in larger pixels, and this approach is better at the higher precision level."
  },
  {
    "objectID": "week7.html#applicaion",
    "href": "week7.html#applicaion",
    "title": "7  Week7: Classification II",
    "section": "7.2 Applicaion",
    "text": "7.2 Applicaion\n\nCase 1: Burlington city land type analysis\n\nSteps:\n\nget EO data of Burlington city (on the border between the states of Iowa and Illinois)\nuse SNIC(Simple Non-Iterative Clustering) for the segmentation\n\n\n\n\nSource: Firigato, 2022\n\n\n\nsample collection, select each class of land use and land cover. typically, 5 classes: Urban, Water, Agriculture, Forestry and Grass.\n\n\n\n\nPoints choosed\n\n\n\nperform the segment classification. the algorithm is Random Forest, result:\n\n\n\n\nResult\n\n\n\nCase 2: Assess building seismic vulnerability\n\nWu et al. (2013) used object-based image analysis (OBIA) that uses high-resolution satellite images to assess building seismic vulnerability. They apply OBIA to extract building features such as height, area, shape, and roof type from satellite images of Guanggu Wuhan, China. They then use these features to classify buildings into different vulnerability classes based on a seismic vulnerability index. They compare their results with field surveys and find that OBIA can provide a reliable and efficient way to map building seismic vulnerability at a large scale.\n\n\n\nArchitecture of assessment. Source: Wu et al., 2013\n\n\nThey used SNIC for segmentation:\n\n\n\nSNIC segmentation\n\n\nAfter analysis, they give a building seismic vulnerability assessment of investigated area, and confirm the grade.\n\n\n\nvulnerability: DG5 > DG4 > DG3"
  },
  {
    "objectID": "week7.html#reflection",
    "href": "week7.html#reflection",
    "title": "7  Week7: Classification II",
    "section": "7.3 Reflection",
    "text": "7.3 Reflection\nIn this week, I feel interested the k-means algorithm when conducting a superpixel analysis. At that time, I found the result of K-means is not good, I want to know the principle of K-means and its substitutes.\n\n7.3.1 Principle of K-means\nK-means partitions a set of data points into k groups, where k is a predefined number. The principle of k-means is to minimize the sum of squared distances between each data point and its closest cluster center. The algorithm works as follows:\nStep 1: Randomly initialize k cluster centers\nStep 2: Assign each data point to the nearest cluster center\nStep 3: Recalculate the cluster centers as the mean of the data points assigned to them\nStep 4: Repeat steps 2 and 3 until convergence or a maximum number of iterations is reached\n\n\n\nK-means example. Source: Researchgate\n\n\n\n\n7.3.2 Improvements\nk-means is suitable for clusters with clear delineation boundaries between each cluster, and the distribution is close to circular, and the amount of data in each cluster is more uniform, so it does not play very well in practical applications.\nThere is an improved clustering algorithm called Gaussian mixture model (GMM), GMM combines several single Gaussian distributions in average and standard deviation, then they have several differences:\n\nK-means assumes that each cluster has a spherical shape and equal size, while GMM assumes that each cluster has an elliptical shape and different size.\nK-means assigns each data point to one and only one cluster center based on the minimum distance, while GMM assigns each data point to multiple cluster centers based on the probability distribution.\nK-means uses an iterative local optimization technique to minimize the sum of squared distances between each data point and its closest cluster center, while GMM uses an expectation-maximization (EM) algorithm to maximize the likelihood of the data given the model parameters.\n\nIn reality, we use GMM to divide clusters that exhibit elliptical data distributions precisely because it is better than K-means\n\n\n\nComparison between GMM and K-means. Source: Amueller"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Firigato, Joao Otavio Nascimento. “Object Based Image Analysis on Google Earth Engine.” Medium, 16 July 2020, joaootavionf007.medium.com/object-based-image-analysis-on-google-earth-engine-1b80e9cb7312.\nGomes, Vitor C. F., et al. “An Overview of Platforms for Big Earth Observation Data Management and Analysis.” Remote Sensing, vol. 12, no. 8, Apr. 2020, p. 1253, doi:https://doi.org/10.3390/rs12081253.\n“How to Cool down Cities and Eliminate Urban Heat Islands.” World Economic Forum, www.weforum.org/agenda/2022/08/ways-to-cool-cities-and-avoid-urban-heat-islands/.\nKarasiak, N., et al. “Spatial Dependence between Training and Test Sets: Another Pitfall of Classification Accuracy Assessment in Remote Sensing.” Machine Learning, vol. 111, no. 7, Apr. 2021, pp. 2715–40, doi:https://doi.org/10.1007/s10994-021-05972-1.\n\nLi, Ying, et al. “Socioeconomic Drivers of Urban Heat Island Effect: Empirical Evidence from Major Chinese Cities.” Sustainable Cities and Society, Aug. 2020, p. 102425, doi:https://doi.org/10.1016/j.scs.2020.102425.\nMahdianpari, M., et al. “A Large-Scale Change Monitoring of Wetlands Using Time Series Landsat Imagery on Google Earth Engine: A Case Study in Newfoundland.” GIScience & Remote Sensing, vol. 57, no. 8, Nov. 2020, pp. 1102–24, doi:https://doi.org/10.1080/15481603.2020.1846948.\nMayer, Timothy, et al. “Deep Learning Approach for Sentinel-1 Surface Water Mapping Leveraging Google Earth Engine.” ISPRS Open Journal of Photogrammetry and Remote Sensing, vol. 2, Dec. 2021, p. 100005, doi:https://doi.org/10.1016/j.ophoto.2021.100005.\nMehmood, Hamid, et al. “Mapping of Flood Areas Using Landsat with Google Earth Engine Cloud Platform.” Atmosphere, vol. 12, no. 7, July 2021, p. 866, doi:https://doi.org/10.3390/atmos12070866.\nNasiri, Vahid, et al. “Land Use and Land Cover Mapping Using Sentinel-2, Landsat-8 Satellite Images, and Google Earth Engine: A Comparison of Two Composition Methods.” Remote Sensing, vol. 14, no. 9, Apr. 2022, p. 1977, doi:https://doi.org/10.3390/rs14091977.\nTuholske, Cascade, et al. “Global Urban Population Exposure to Extreme Heat.” Proceedings of the National Academy of Sciences, vol. 118, no. 41, Oct. 2021, p. e2024792118, doi:https://doi.org/10.1073/pnas.2024792118.\nWu, Hao, et al. “An Object-Based Image Analysis for Building Seismic Vulnerability Assessment Using High-Resolution Remote Sensing Imagery.” Natural Hazards, vol. 71, no. 1, Oct. 2013, pp. 151–74, doi:https://doi.org/10.1007/s11069-013-0905-6."
  }
]